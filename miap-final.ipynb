{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11445212,"sourceType":"datasetVersion","datasetId":7170162}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, applications\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import f1_score, roc_auc_score\nfrom datetime import datetime\nimport traceback\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n# Set random seeds for reproducibility\ntf.random.set_seed(42)\nnp.random.seed(42)","metadata":{"_uuid":"e6f92dde-d5c7-45c3-9bc8-a18cc69b35c9","_cell_guid":"afcf9e67-551f-438b-97f5-22a51625bc74","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-04T01:52:17.064389Z","iopub.execute_input":"2025-06-04T01:52:17.064599Z","iopub.status.idle":"2025-06-04T01:52:33.354390Z","shell.execute_reply.started":"2025-06-04T01:52:17.064560Z","shell.execute_reply":"2025-06-04T01:52:33.353809Z"}},"outputs":[{"name":"stderr","text":"2025-06-04 01:52:20.735594: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749001940.968977      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749001941.037420      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"TRAIN_CSV = \"/kaggle/input/miap-dataset/fixedTraindataset.csv\"\nVAL_CSV = \"/kaggle/input/miap-dataset/fixedVALdataset.csv\"\nTEST_CSV = \"/kaggle/input/miap-dataset/fixedTestdataset.csv\"\n\nIMAGE_DIRS = {\n    'train': \"/kaggle/input/miap-dataset/processed_train\",\n    'val': \"/kaggle/input/miap-dataset/processed_val\",\n    'test': \"/kaggle/input/miap-dataset/processed_test\"\n}\n\nCLASSES_TO_EXCLUDE = [\"No Finding\"]\nIMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS =  30\nGRADCAM_SAMPLES = 5\n\n# Create output directories\nos.makedirs(\"/kaggle/working/models\", exist_ok=True)\nos.makedirs(\"/kaggle/working/gradcam\", exist_ok=True)\nos.makedirs(\"/kaggle/working/logs\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:52:33.360029Z","iopub.execute_input":"2025-06-04T01:52:33.360223Z","iopub.status.idle":"2025-06-04T01:52:33.365270Z","shell.execute_reply.started":"2025-06-04T01:52:33.360208Z","shell.execute_reply":"2025-06-04T01:52:33.364509Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def load_and_validate_data():\n    \"\"\"Load data and validate all image paths exist\"\"\"\n    def validate_paths(df, mode):\n        valid_entries = []\n        for _, row in df.iterrows():\n            filename = row[\"File Name\"]\n            # Check multiple extensions\n            for ext in ['', '.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n                test_path = os.path.join(IMAGE_DIRS[mode], f\"{os.path.splitext(filename)[0]}{ext}\")\n                if os.path.exists(test_path):\n                    valid_entries.append({\n                        'path': test_path,\n                        'filename': filename,\n                        'labels': row[\"Combined Labels\"]\n                    })\n                    break\n        return pd.DataFrame(valid_entries)\n\n    print(\"Loading and validating training data...\")\n    train_df = pd.read_csv(TRAIN_CSV)\n    train_df = validate_paths(train_df, 'train')\n    \n    print(\"Loading and validating validation data...\")\n    val_df = pd.read_csv(VAL_CSV)\n    val_df = validate_paths(val_df, 'val')\n    \n    print(\"Loading and validating test data...\")\n    test_df = pd.read_csv(TEST_CSV)\n    test_df = validate_paths(test_df, 'test')\n    \n    # Process labels\n    def split_labels(label_str):\n        if pd.isna(label_str):\n            return []\n        return [label.strip() for label in str(label_str).split(\"|\") if label.strip() not in CLASSES_TO_EXCLUDE]\n    \n    train_df['labels'] = train_df['labels'].apply(split_labels)\n    val_df['labels'] = val_df['labels'].apply(split_labels)\n    test_df['labels'] = test_df['labels'].apply(split_labels)\n    \n    # Get all unique classes\n    all_labels = []\n    for df in [train_df, val_df, test_df]:\n        all_labels.extend([label for sublist in df['labels'] for label in sublist])\n    classes = sorted(list(set(all_labels) - set(CLASSES_TO_EXCLUDE)))\n    \n    # Create MultiLabelBinarizer\n    mlb = MultiLabelBinarizer()\n    mlb.fit([classes])  # Fit with all possible classes\n    \n    return train_df, val_df, test_df, classes, mlb\n\ntrain_df, val_df, test_df, classes, mlb = load_and_validate_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:52:33.602263Z","iopub.execute_input":"2025-06-04T01:52:33.602738Z","iopub.status.idle":"2025-06-04T02:00:08.431532Z","shell.execute_reply.started":"2025-06-04T01:52:33.602720Z","shell.execute_reply":"2025-06-04T02:00:08.430936Z"}},"outputs":[{"name":"stdout","text":"Loading and validating training data...\nLoading and validating validation data...\nLoading and validating test data...\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def create_class_dataset(df, class_name, mode, augment=False):\n    \"\"\"Create balanced dataset for a specific class with validation checks\"\"\"\n    valid_samples = []\n    for _, row in df.iterrows():\n        if row['path']:\n            label = 1 if class_name in row['labels'] else 0\n            valid_samples.append((row['path'], row['filename'], label))\n    \n    pos_samples = [x for x in valid_samples if x[2] == 1]\n    neg_samples = [x for x in valid_samples if x[2] == 0]\n    \n    if not pos_samples or not neg_samples:\n        raise ValueError(f\"Insufficient samples for {class_name} - Pos: {len(pos_samples)}, Neg: {len(neg_samples)}\")\n    \n    n_samples = min(len(pos_samples), len(neg_samples))\n    balanced_samples = pos_samples[:n_samples] + neg_samples[:n_samples]\n    np.random.shuffle(balanced_samples)\n    \n    if mode == 'val':\n        val_pos = sum(1 for _, _, label in balanced_samples if label == 1)\n        print(f\"Validation balance - Pos: {val_pos}, Neg: {len(balanced_samples)-val_pos}\")\n        if val_pos == 0 or val_pos == len(balanced_samples):\n            raise ValueError(f\"Invalid validation distribution for {class_name}\")\n    \n    def load_image(path, filename, label):\n        img = tf.io.read_file(path)\n        img = tf.image.decode_jpeg(img, channels=3)\n        img = tf.image.resize(img, IMAGE_SIZE)\n        img = tf.keras.applications.densenet.preprocess_input(img)\n        if augment:\n            img = tf.image.random_flip_left_right(img)\n            img = tf.image.random_brightness(img, 0.1)\n            img = tf.image.random_contrast(img, 0.9, 1.1)\n        return img, filename, tf.cast(label, tf.float32)\n    \n    paths, filenames, labels = zip(*balanced_samples)\n    dataset = tf.data.Dataset.from_tensor_slices((list(paths), list(filenames), list(labels)))\n    dataset = dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n    return dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T02:00:08.432655Z","iopub.execute_input":"2025-06-04T02:00:08.432903Z","iopub.status.idle":"2025-06-04T02:00:08.441793Z","shell.execute_reply.started":"2025-06-04T02:00:08.432875Z","shell.execute_reply":"2025-06-04T02:00:08.441102Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"LEARNING_RATE = 2e-4  # Reduced initial learning rate\nDROPOUT_RATE = 0.6\nclass DenseNetWithHead(tf.keras.Model):\n    def __init__(self, image_size):\n        super().__init__()\n        self.base_model = tf.keras.applications.DenseNet121(\n            include_top=False,\n            weights=\"imagenet\",\n            input_shape=(*image_size, 3),\n            pooling=None\n        )\n        for layer in self.base_model.layers[-20:]:\n            if not isinstance(layer, tf.keras.layers.BatchNormalization):\n                layer.trainable = True\n                \n        self.gap = tf.keras.layers.GlobalAveragePooling2D()\n        self.drop = tf.keras.layers.Dropout(0.5)\n        self.head = tf.keras.layers.Dense(1, activation='sigmoid')\n        self._gradcam_layer_name = 'conv5_block16_2_conv'\n        self._base_model = self.base_model\n\n    def call(self, inputs, training=False):\n        x = self.base_model(inputs, training=training)\n        x = self.gap(x)\n        x = self.drop(x, training=training)\n        return self.head(x)\n\ndef build_densenet_model():\n    model = DenseNetWithHead(IMAGE_SIZE)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n        loss=tf.keras.losses.BinaryFocalCrossentropy(from_logits=False, gamma=2.0),\n        metrics=[\n            tf.keras.metrics.AUC(name='auc'),\n            tf.keras.metrics.BinaryAccuracy(name='acc'),\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall')\n        ]\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T02:00:08.442483Z","iopub.execute_input":"2025-06-04T02:00:08.442690Z","iopub.status.idle":"2025-06-04T02:00:08.463762Z","shell.execute_reply.started":"2025-06-04T02:00:08.442666Z","shell.execute_reply":"2025-06-04T02:00:08.463127Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def train_single_class(class_name):\n    \"\"\"Train model for a single class\"\"\"\n    print(f\"\\n=== Training model for: {class_name} ===\")\n    print(f\"Started at {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC\")\n    \n    try:\n        # Create datasets\n        train_ds = create_class_dataset(train_df, class_name, 'train', augment=True)\n        val_ds = create_class_dataset(val_df, class_name, 'val')\n        val_labels = np.array([y.numpy() for _, _, y in val_ds.unbatch()])\n        pos_ratio = np.mean(val_labels)\n        \n        if pos_ratio < 0.2 or pos_ratio > 0.8:\n            print(f\"Skipping {class_name} - imbalanced validation set ({pos_ratio:.2f} positive)\")\n            return None\n            \n        # Build model\n        print(f\"Building model for {class_name}...\")\n        model = build_densenet_model()\n        \n        # Initialize with dummy input\n        print(\"Initializing model with dummy input...\")\n        dummy = tf.zeros((1, *IMAGE_SIZE, 3))\n        _ = model(dummy, training=False)\n        \n        # Calculate class weights\n        pos_count = train_df['labels'].apply(lambda x: class_name in x).sum()\n        pos_weight = (len(train_df) - pos_count) / max(1, pos_count)\n        \n        callbacks = [\n            tf.keras.callbacks.EarlyStopping(\n                patience=5,\n                monitor='val_auc',\n                mode='max',\n                restore_best_weights=True,\n                baseline=0.7\n            ),\n            tf.keras.callbacks.ModelCheckpoint(\n                f\"/kaggle/working/models/{class_name}_model.keras\",\n                monitor='val_auc',\n                save_best_only=True,\n                mode='max'\n            ),\n            tf.keras.callbacks.ReduceLROnPlateau(\n                monitor='val_loss',\n                factor=0.5,\n                patience=2,\n                min_lr=1e-6,\n                verbose=1\n            ),\n            tf.keras.callbacks.CSVLogger(\n                f\"/kaggle/working/logs/{class_name}_history.csv\"\n            )\n        ]\n\n        print(f\"Training samples: {len(list(train_ds))} batches\")\n        print(f\"Validation samples: {len(list(val_ds))} batches\")\n        print(f\"Using class weight - positive: {pos_weight:.2f}\")\n\n        # Train\n        history = model.fit(\n            train_ds.map(lambda img, filename, label: (img, label)),\n            validation_data=val_ds.map(lambda img, filename, label: (img, label)),\n            epochs=EPOCHS,\n            callbacks=callbacks,\n            verbose=1,\n            class_weight={0: 1., 1: pos_weight}\n        )\n\n        # Find best threshold\n        val_probs = model.predict(val_ds.map(lambda img, filename, label: (img, label)))\n        val_labels = np.array([y.numpy() for _, y in val_ds.map(lambda img, filename, label: (img, label)).unbatch()])\n        \n        best_threshold = 0.5\n        best_f1 = 0\n        for threshold in np.linspace(0.1, 0.9, 17):\n            current_f1 = f1_score(val_labels, val_probs > threshold)\n            if current_f1 > best_f1:\n                best_f1 = current_f1\n                best_threshold = threshold\n                \n        results = {\n            'best_f1': float(best_f1),\n            'best_threshold': float(best_threshold),\n            'train_samples': len(list(train_ds)) * BATCH_SIZE,\n            'val_samples': len(val_labels),\n            'val_pos_ratio': float(np.mean(val_labels))\n        }\n        \n        print(f\"Best threshold: {best_threshold:.3f} (F1: {best_f1:.3f})\")\n        \n        # Generate GradCAM\n        print(\"Generating GradCAM visualizations...\")\n        save_gradcam_images(model, val_ds, class_name, best_threshold)\n        \n        print(f\"Completed at {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC\")\n        return results\n        \n    except Exception as e:\n        print(f\"Error training {class_name}: {str(e)}\")\n        print(f\"Exception type: {type(e)}\")\n        print(f\"Traceback:\\n{traceback.format_exc()}\")\n        return None","metadata":{"_uuid":"f37a8c8e-5c1c-4f61-8ffe-f0c6cc183375","_cell_guid":"1ab4326a-5340-4ebe-940e-248d8e5a1349","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-04T02:00:08.465192Z","iopub.execute_input":"2025-06-04T02:00:08.465389Z","iopub.status.idle":"2025-06-04T02:00:08.485375Z","shell.execute_reply.started":"2025-06-04T02:00:08.465374Z","shell.execute_reply":"2025-06-04T02:00:08.484848Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def generate_gradcam(model, img_array):\n    \"\"\"Generate Grad-CAM heatmap with explicit tensor operations\"\"\"\n    try:\n        # Get the base model and conv layer\n        base_model = model.base_model  # Using base_model instead of _base_model\n        conv_layer = base_model.get_layer(model._gradcam_layer_name)\n        \n        # Create a model that goes from input to conv layer\n        grad_model = tf.keras.Model(\n            inputs=base_model.input,\n            outputs=[\n                conv_layer.output,\n                base_model.output\n            ]\n        )\n        \n        # Record operations for gradient computation\n        with tf.GradientTape() as tape:\n            # Forward pass through base model to get conv outputs\n            inputs = tf.cast(img_array, tf.float32)\n            conv_output, base_output = grad_model(inputs, training=False)\n            \n            # Forward pass through remaining layers\n            x = model.gap(base_output)\n            x = model.drop(x, training=False)\n            predictions = model.head(x)\n            \n            # Get the score for the target class\n            score = predictions[:, 0]\n        \n        # Calculate gradients\n        grads = tape.gradient(score, conv_output)\n        \n        # Global average pooling\n        pooled_grads = tf.reduce_mean(grads, axis=(1, 2))\n        \n        # Weight the channels and create heatmap\n        conv_output = conv_output[0]\n        pooled_grads = pooled_grads[0]\n        \n        # Apply weights to create heatmap\n        heatmap = tf.zeros_like(conv_output[:, :, 0])\n        for i in range(pooled_grads.shape[-1]):\n            heatmap += conv_output[:, :, i] * pooled_grads[i]\n        \n        # Post-process heatmap\n        heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + tf.keras.backend.epsilon())\n        \n        return heatmap.numpy()\n        \n    except Exception as e:\n        print(f\"Error in generate_gradcam: {str(e)}\")\n        print(f\"Conv layer name: {model._gradcam_layer_name}\")\n        print(f\"Base model layers: {[layer.name for layer in model.base_model.layers]}\")\n        raise","metadata":{"_uuid":"a5e1fac2-5a28-4ce0-ada6-c39526463121","_cell_guid":"38495ffd-4559-4ebf-89f2-9ff357d9a0ff","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-04T02:00:08.486079Z","iopub.execute_input":"2025-06-04T02:00:08.486300Z","iopub.status.idle":"2025-06-04T02:00:08.504129Z","shell.execute_reply.started":"2025-06-04T02:00:08.486277Z","shell.execute_reply":"2025-06-04T02:00:08.503585Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def save_gradcam_images(model, dataset, class_name, threshold, num_images=5):\n    \"\"\"Save Grad-CAM visualizations with improved error handling\"\"\"\n    try:\n        os.makedirs(\"/kaggle/working/gradcam/\", exist_ok=True)\n        \n        for batch in dataset.take(1):\n            images, filenames, _ = batch\n            \n            for i in range(min(num_images, len(images))):\n                try:\n                    img = images[i]\n                    filename = filenames[i]\n                    \n                    # Ensure input is in the correct format\n                    img_array = tf.expand_dims(img, axis=0)\n                    img_array = tf.cast(img_array, tf.float32)\n                    \n                    print(f\"Processing image {i+1}/{min(num_images, len(images))}...\")\n                    print(f\"Input shape: {img_array.shape}\")\n                    \n                    # Generate heatmap\n                    heatmap = generate_gradcam(model, img_array)\n                    \n                    if heatmap is None:\n                        print(f\"Warning: Heatmap generation failed for image {i+1}\")\n                        continue\n                        \n                    print(f\"Heatmap shape: {heatmap.shape}\")\n                    \n                    # Resize heatmap to match input image size\n                    heatmap_resized = cv2.resize(heatmap, (IMAGE_SIZE[1], IMAGE_SIZE[0]))\n                    heatmap_uint8 = np.uint8(255 * heatmap_resized)\n                    heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n                    \n                    # Process original image\n                    orig_img = img.numpy()\n                    orig_img = ((orig_img + 1) * 127.5).astype('uint8')\n                    \n                    # Create overlay\n                    superimposed = cv2.addWeighted(orig_img, 0.6, heatmap_colored, 0.4, 0)\n                    \n                    # Save output\n                    output_path = f\"/kaggle/working/gradcam/{class_name}_{filename.numpy().decode('utf-8')}\"\n                    cv2.imwrite(output_path, superimposed)\n                    print(f\"Saved visualization to {output_path}\")\n                    \n                except Exception as e:\n                    print(f\"Error processing image {i+1}: {str(e)}\")\n                    continue\n                    \n    except Exception as e:\n        print(f\"Error in save_gradcam_images: {str(e)}\")\n        raise","metadata":{"_uuid":"08d08bb1-a088-437f-8b0c-ede208582ecf","_cell_guid":"0887440d-fa25-465a-8a48-444dd3160bf0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-04T02:00:08.504857Z","iopub.execute_input":"2025-06-04T02:00:08.505122Z","iopub.status.idle":"2025-06-04T02:00:08.521658Z","shell.execute_reply.started":"2025-06-04T02:00:08.505104Z","shell.execute_reply":"2025-06-04T02:00:08.521155Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def evaluate_models():\n    with open(\"/kaggle/working/thresholds.json\", \"r\") as f:\n        thresholds = json.load(f)\n    \n    # Prepare test data\n    test_labels = mlb.transform(test_df['labels'])\n    all_preds = np.zeros((len(test_df), len(classes)))\n    all_probs = np.zeros((len(test_df), len(classes)))\n    \n    for class_idx, class_name in enumerate(classes):\n        model_path = f\"/kaggle/working/models/{class_name}_model.keras\"\n        if not os.path.exists(model_path):\n            print(f\"Skipping {class_name} - model not found\")\n            continue\n            \n        print(f\"Evaluating {class_name}...\")\n        model = tf.keras.models.load_model(model_path)\n        \n        # Create test dataset\n        try:\n            test_ds = create_class_dataset(test_df, class_name, 'test')\n        except ValueError as e:\n            print(f\"Skipping {class_name}: {str(e)}\")\n            continue\n        \n        # Predict\n        probs = model.predict(test_ds.map(lambda img, filename, label: (img, label)))\n        preds = (probs > thresholds[class_name]).astype(int)\n        \n        # Store results\n        all_probs[:, class_idx] = probs.flatten()\n        all_preds[:, class_idx] = preds.flatten()\n        \n        # Generate Grad-CAM for test samples\n        save_gradcam_images(model, test_ds, class_name, thresholds[class_name])\n    \n    # Calculate metrics\n    results = {\n        'micro_f1': f1_score(test_labels, all_preds, average='micro'),\n        'macro_f1': f1_score(test_labels, all_preds, average='macro'),\n        'micro_auc': roc_auc_score(test_labels, all_probs, average='micro'),\n        'macro_auc': roc_auc_score(test_labels, all_probs, average='macro')\n    }\n    \n    print(\"\\nTest Set Metrics:\")\n    for metric, value in results.items():\n        print(f\"{metric}: {value:.4f}\")\n    \n    # Save predictions\n    results_df = pd.DataFrame({\n        'File_Name': test_df['filename'],\n        **{f'prob_{class_name}': all_probs[:, i] for i, class_name in enumerate(classes)},\n        **{f'pred_{class_name}': all_preds[:, i] for i, class_name in enumerate(classes)}\n    })\n    results_df.to_csv(\"/kaggle/working/predictions.csv\", index=False)\n    \n    with open(\"/kaggle/working/test_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"_uuid":"7a5e073c-4a9e-4b90-ad10-438cb6cfad24","_cell_guid":"04f73e9a-6995-4d1f-acae-b5a86469dc04","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-04T02:00:08.522456Z","iopub.execute_input":"2025-06-04T02:00:08.523082Z","iopub.status.idle":"2025-06-04T02:00:08.542361Z","shell.execute_reply.started":"2025-06-04T02:00:08.523066Z","shell.execute_reply":"2025-06-04T02:00:08.541831Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\n\n# Get unique classes from training data\nunique_classes = set()\nfor labels in train_df['labels'].values:\n    if isinstance(labels, str):  # If labels are stored as strings\n        unique_classes.update(labels.split('|'))\n    elif isinstance(labels, list):  # If labels are stored as lists\n        unique_classes.update(labels)\n\n# Sort classes alphabetically\nclasses = sorted(list(unique_classes))\n\nprint(\"Classes found in training data:\")\nprint(\"=\" * 40)\nfor i, class_name in enumerate(classes, 1):\n    print(f\"{i:2d}. {class_name}\")\nprint(\"=\" * 40)\nprint(f\"Total number of classes: {len(classes)}\")\n\n# Store for future use\nwith open(\"/kaggle/working/classes.json\", \"w\") as f:\n    json.dump(classes, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T15:24:58.907705Z","iopub.execute_input":"2025-06-03T15:24:58.908182Z","iopub.status.idle":"2025-06-03T15:24:58.941848Z","shell.execute_reply.started":"2025-06-03T15:24:58.908163Z","shell.execute_reply":"2025-06-03T15:24:58.941312Z"}},"outputs":[{"name":"stdout","text":"Classes found in training data:\n========================================\n 1. Atelectasis\n 2. COVID-19\n 3. Cardiomegaly\n 4. Consolidation\n 5. Edema\n 6. Effusion\n 7. Emphysema\n 8. Fibrosis\n 9. Hernia\n10. Infiltration\n11. Mass\n12. Nodule\n13. Pleural_Thickening\n14. Pneumonia\n15. Pneumothorax\n========================================\nTotal number of classes: 15\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Train 1\nresults = train_single_class('Atelectasis')\nif results:\n    with open(\"/kaggle/working/Atelectasis_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T15:25:26.873403Z","iopub.execute_input":"2025-06-03T15:25:26.873653Z","iopub.status.idle":"2025-06-03T15:54:10.881825Z","shell.execute_reply.started":"2025-06-03T15:25:26.873637Z","shell.execute_reply":"2025-06-03T15:54:10.881165Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Atelectasis ===\nStarted at 2025-06-03 15:25:26 UTC\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1748964330.866195      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1748964330.866935      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Validation balance - Pos: 2342, Neg: 2342\nBuilding model for Atelectasis...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nInitializing model with dummy input...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1748964350.766907      31 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"Training samples: 434 batches\nValidation samples: 147 batches\nUsing class weight - positive: 8.73\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1748964491.211984     107 service.cc:148] XLA service 0x7c8b54001540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1748964491.212733     107 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1748964491.213054     107 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1748964580.504166     107 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 533ms/step - acc: 0.5488 - auc: 0.6014 - loss: 0.8547 - precision: 0.5315 - recall: 0.8817 - val_acc: 0.5111 - val_auc: 0.7218 - val_loss: 0.5181 - val_precision: 0.5056 - val_recall: 0.9983 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 303ms/step - acc: 0.5661 - auc: 0.6719 - loss: 0.5045 - precision: 0.5383 - recall: 0.9543 - val_acc: 0.5102 - val_auc: 0.7413 - val_loss: 0.4754 - val_precision: 0.5052 - val_recall: 0.9983 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 304ms/step - acc: 0.5831 - auc: 0.7291 - loss: 0.4403 - precision: 0.5482 - recall: 0.9659 - val_acc: 0.5152 - val_auc: 0.7442 - val_loss: 0.3771 - val_precision: 0.5077 - val_recall: 0.9991 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 300ms/step - acc: 0.6001 - auc: 0.7632 - loss: 0.3962 - precision: 0.5585 - recall: 0.9717 - val_acc: 0.5047 - val_auc: 0.7336 - val_loss: 0.3772 - val_precision: 0.5024 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 5/30\n\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 303ms/step - acc: 0.6161 - auc: 0.7968 - loss: 0.3649 - precision: 0.5685 - recall: 0.9782 - val_acc: 0.5741 - val_auc: 0.7512 - val_loss: 0.2940 - val_precision: 0.5407 - val_recall: 0.9846 - learning_rate: 2.0000e-04\nEpoch 6/30\n\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 299ms/step - acc: 0.6425 - auc: 0.8279 - loss: 0.3386 - precision: 0.5865 - recall: 0.9773 - val_acc: 0.5201 - val_auc: 0.7393 - val_loss: 0.4226 - val_precision: 0.5103 - val_recall: 0.9966 - learning_rate: 2.0000e-04\nEpoch 7/30\n\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 299ms/step - acc: 0.6763 - auc: 0.8542 - loss: 0.3101 - precision: 0.6104 - recall: 0.9827 - val_acc: 0.5995 - val_auc: 0.7288 - val_loss: 0.2920 - val_precision: 0.5600 - val_recall: 0.9287 - learning_rate: 2.0000e-04\nEpoch 8/30\n\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 299ms/step - acc: 0.7068 - auc: 0.8757 - loss: 0.2846 - precision: 0.6343 - recall: 0.9826 - val_acc: 0.6223 - val_auc: 0.7399 - val_loss: 0.3756 - val_precision: 0.5736 - val_recall: 0.9530 - learning_rate: 2.0000e-04\nEpoch 9/30\n\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 299ms/step - acc: 0.7297 - auc: 0.8987 - loss: 0.2607 - precision: 0.6532 - recall: 0.9846 - val_acc: 0.6763 - val_auc: 0.7456 - val_loss: 0.2360 - val_precision: 0.6588 - val_recall: 0.7314 - learning_rate: 2.0000e-04\nEpoch 10/30\n\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 299ms/step - acc: 0.7465 - auc: 0.9172 - loss: 0.2425 - precision: 0.6688 - recall: 0.9814 - val_acc: 0.6332 - val_auc: 0.7243 - val_loss: 0.2540 - val_precision: 0.5888 - val_recall: 0.8834 - learning_rate: 2.0000e-04\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 144ms/step\nBest threshold: 0.650 (F1: 0.724)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Atelectasis_00009030_004.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Atelectasis_00013052_006.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Atelectasis_00016270_001.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Atelectasis_00002583_004.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Atelectasis_00006642_029.png\nCompleted at 2025-06-03 15:54:10 UTC\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Train 2\nresults = train_single_class('COVID-19')\nif results:\n    with open(\"/kaggle/working/COVID-19_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T15:57:28.499014Z","iopub.execute_input":"2025-06-03T15:57:28.499631Z","iopub.status.idle":"2025-06-03T16:03:22.225516Z","shell.execute_reply.started":"2025-06-03T15:57:28.499607Z","shell.execute_reply":"2025-06-03T16:03:22.224734Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: COVID-19 ===\nStarted at 2025-06-03 15:57:28 UTC\nValidation balance - Pos: 74, Neg: 74\nBuilding model for COVID-19...\nInitializing model with dummy input...\nTraining samples: 15 batches\nValidation samples: 5 batches\nUsing class weight - positive: 298.96\nEpoch 1/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 8s/step - acc: 0.7383 - auc: 0.8633 - loss: 46.1934 - precision: 0.7950 - recall: 0.6617 - val_acc: 0.5000 - val_auc: 0.5676 - val_loss: 3.6436 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 396ms/step - acc: 0.9348 - auc: 0.9991 - loss: 0.4922 - precision: 0.8890 - recall: 0.9994 - val_acc: 0.5000 - val_auc: 0.8446 - val_loss: 2.0857 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 388ms/step - acc: 0.9102 - auc: 0.9940 - loss: 0.2086 - precision: 0.8549 - recall: 0.9994 - val_acc: 0.5676 - val_auc: 0.9974 - val_loss: 0.5509 - val_precision: 1.0000 - val_recall: 0.1351 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 292ms/step - acc: 0.9048 - auc: 0.9930 - loss: 0.5803 - precision: 0.8489 - recall: 0.9976 - val_acc: 0.6689 - val_auc: 0.9953 - val_loss: 0.2971 - val_precision: 1.0000 - val_recall: 0.3378 - learning_rate: 2.0000e-04\nEpoch 5/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 290ms/step - acc: 0.8640 - auc: 0.9769 - loss: 0.4582 - precision: 0.7976 - recall: 0.9982 - val_acc: 0.6216 - val_auc: 0.9854 - val_loss: 0.2487 - val_precision: 1.0000 - val_recall: 0.2432 - learning_rate: 2.0000e-04\nEpoch 6/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 293ms/step - acc: 0.8163 - auc: 0.9695 - loss: 1.2296 - precision: 0.7449 - recall: 0.9878 - val_acc: 0.8716 - val_auc: 0.9931 - val_loss: 0.0791 - val_precision: 0.9825 - val_recall: 0.7568 - learning_rate: 2.0000e-04\nEpoch 7/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 289ms/step - acc: 0.8183 - auc: 0.9888 - loss: 0.2710 - precision: 0.7424 - recall: 0.9994 - val_acc: 0.9122 - val_auc: 0.9937 - val_loss: 0.0393 - val_precision: 0.9692 - val_recall: 0.8514 - learning_rate: 2.0000e-04\nEpoch 8/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 289ms/step - acc: 0.7790 - auc: 0.9840 - loss: 0.2630 - precision: 0.7031 - recall: 1.0000 - val_acc: 0.9662 - val_auc: 0.9915 - val_loss: 0.0265 - val_precision: 0.9600 - val_recall: 0.9730 - learning_rate: 2.0000e-04\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step\nBest threshold: 0.100 (F1: 0.896)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/COVID-19_00013911_005.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/COVID-19_00028300_004.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/COVID-19_5.jpg\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/COVID-19_187.jpg\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/COVID-19_244.jpg\nCompleted at 2025-06-03 16:03:22 UTC\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Train 3\nresults = train_single_class('Cardiomegaly')\nif results:\n    with open(\"/kaggle/working/Cardiomegaly_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:03:22.226794Z","iopub.execute_input":"2025-06-03T16:03:22.227273Z","iopub.status.idle":"2025-06-03T16:16:56.100505Z","shell.execute_reply.started":"2025-06-03T16:03:22.227255Z","shell.execute_reply":"2025-06-03T16:16:56.099802Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Cardiomegaly ===\nStarted at 2025-06-03 16:03:22 UTC\nValidation balance - Pos: 504, Neg: 504\nBuilding model for Cardiomegaly...\nInitializing model with dummy input...\nTraining samples: 104 batches\nValidation samples: 32 batches\nUsing class weight - positive: 39.90\nEpoch 1/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 2s/step - acc: 0.5348 - auc: 0.5726 - loss: 3.7709 - precision: 0.5257 - recall: 0.8254 - val_acc: 0.5774 - val_auc: 0.6548 - val_loss: 0.3101 - val_precision: 0.6741 - val_recall: 0.2996 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 318ms/step - acc: 0.5507 - auc: 0.6792 - loss: 1.0528 - precision: 0.5290 - recall: 0.9777 - val_acc: 0.6657 - val_auc: 0.7593 - val_loss: 0.2871 - val_precision: 0.6069 - val_recall: 0.9405 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 309ms/step - acc: 0.5814 - auc: 0.7498 - loss: 0.8111 - precision: 0.5463 - recall: 0.9923 - val_acc: 0.6171 - val_auc: 0.8330 - val_loss: 0.4649 - val_precision: 0.5670 - val_recall: 0.9901 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - acc: 0.5957 - auc: 0.7667 - loss: 0.7757 - precision: 0.5554 - recall: 0.9897\nEpoch 4: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 299ms/step - acc: 0.5957 - auc: 0.7670 - loss: 0.7753 - precision: 0.5554 - recall: 0.9897 - val_acc: 0.5675 - val_auc: 0.7934 - val_loss: 0.9039 - val_precision: 0.5362 - val_recall: 0.9980 - learning_rate: 2.0000e-04\nEpoch 5/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 296ms/step - acc: 0.6414 - auc: 0.8448 - loss: 0.6176 - precision: 0.5846 - recall: 0.9936 - val_acc: 0.5982 - val_auc: 0.8191 - val_loss: 0.7950 - val_precision: 0.5547 - val_recall: 0.9960 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - acc: 0.6752 - auc: 0.8844 - loss: 0.5540 - precision: 0.6095 - recall: 0.9879\nEpoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 311ms/step - acc: 0.6751 - auc: 0.8844 - loss: 0.5538 - precision: 0.6094 - recall: 0.9879 - val_acc: 0.6538 - val_auc: 0.8584 - val_loss: 0.3470 - val_precision: 0.5939 - val_recall: 0.9722 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 312ms/step - acc: 0.7179 - auc: 0.9126 - loss: 0.4321 - precision: 0.6414 - recall: 0.9964 - val_acc: 0.6538 - val_auc: 0.8617 - val_loss: 0.3752 - val_precision: 0.5944 - val_recall: 0.9683 - learning_rate: 5.0000e-05\nEpoch 8/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 312ms/step - acc: 0.7468 - auc: 0.9273 - loss: 0.3947 - precision: 0.6661 - recall: 0.9959 - val_acc: 0.7054 - val_auc: 0.8663 - val_loss: 0.2729 - val_precision: 0.6356 - val_recall: 0.9623 - learning_rate: 5.0000e-05\nEpoch 9/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 311ms/step - acc: 0.7550 - auc: 0.9418 - loss: 0.3755 - precision: 0.6742 - recall: 0.9941 - val_acc: 0.6696 - val_auc: 0.8699 - val_loss: 0.4058 - val_precision: 0.6054 - val_recall: 0.9742 - learning_rate: 5.0000e-05\nEpoch 10/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - acc: 0.7896 - auc: 0.9594 - loss: 0.3007 - precision: 0.7065 - recall: 0.9955\nEpoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 297ms/step - acc: 0.7896 - auc: 0.9595 - loss: 0.3007 - precision: 0.7065 - recall: 0.9955 - val_acc: 0.6746 - val_auc: 0.8669 - val_loss: 0.5059 - val_precision: 0.6086 - val_recall: 0.9782 - learning_rate: 5.0000e-05\nEpoch 11/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 296ms/step - acc: 0.8023 - auc: 0.9653 - loss: 0.2686 - precision: 0.7196 - recall: 0.9952 - val_acc: 0.7401 - val_auc: 0.8670 - val_loss: 0.3342 - val_precision: 0.6734 - val_recall: 0.9325 - learning_rate: 2.5000e-05\nEpoch 12/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - acc: 0.8413 - auc: 0.9788 - loss: 0.2340 - precision: 0.7615 - recall: 0.9967\nEpoch 12: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 296ms/step - acc: 0.8412 - auc: 0.9788 - loss: 0.2344 - precision: 0.7615 - recall: 0.9967 - val_acc: 0.7371 - val_auc: 0.8545 - val_loss: 0.2947 - val_precision: 0.6739 - val_recall: 0.9187 - learning_rate: 2.5000e-05\nEpoch 13/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 297ms/step - acc: 0.8227 - auc: 0.9784 - loss: 0.2150 - precision: 0.7412 - recall: 0.9964 - val_acc: 0.7272 - val_auc: 0.8683 - val_loss: 0.3550 - val_precision: 0.6615 - val_recall: 0.9306 - learning_rate: 1.2500e-05\nEpoch 14/30\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - acc: 0.8575 - auc: 0.9855 - loss: 0.1956 - precision: 0.7804 - recall: 0.9974\nEpoch 14: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 296ms/step - acc: 0.8576 - auc: 0.9855 - loss: 0.1953 - precision: 0.7805 - recall: 0.9974 - val_acc: 0.7460 - val_auc: 0.8641 - val_loss: 0.3210 - val_precision: 0.6834 - val_recall: 0.9167 - learning_rate: 1.2500e-05\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 448ms/step\nBest threshold: 0.750 (F1: 0.794)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Cardiomegaly_00008649_000.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Cardiomegaly_00000514_002.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Cardiomegaly_00010805_018.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Cardiomegaly_00023131_000.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Cardiomegaly_00017999_006.png\nCompleted at 2025-06-03 16:16:56 UTC\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Train 4\nresults = train_single_class('Consolidation')\nif results:\n    with open(\"/kaggle/working/Consolidation_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:18:09.995596Z","iopub.execute_input":"2025-06-03T16:18:09.996455Z","iopub.status.idle":"2025-06-03T16:32:08.659752Z","shell.execute_reply.started":"2025-06-03T16:18:09.996430Z","shell.execute_reply":"2025-06-03T16:32:08.658905Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Consolidation ===\nStarted at 2025-06-03 16:18:09 UTC\nValidation balance - Pos: 945, Neg: 945\nBuilding model for Consolidation...\nInitializing model with dummy input...\nTraining samples: 176 batches\nValidation samples: 60 batches\nUsing class weight - positive: 23.06\nEpoch 1/30\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 835ms/step - acc: 0.5461 - auc: 0.5961 - loss: 1.5431 - precision: 0.5245 - recall: 0.8980 - val_acc: 0.5000 - val_auc: 0.6833 - val_loss: 1.0220 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 310ms/step - acc: 0.5164 - auc: 0.6445 - loss: 0.8529 - precision: 0.5058 - recall: 0.9769 - val_acc: 0.5005 - val_auc: 0.7494 - val_loss: 0.4874 - val_precision: 0.5003 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 297ms/step - acc: 0.5204 - auc: 0.6897 - loss: 0.7154 - precision: 0.5080 - recall: 0.9872 - val_acc: 0.5016 - val_auc: 0.7346 - val_loss: 0.7058 - val_precision: 0.5008 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - acc: 0.5262 - auc: 0.7217 - loss: 0.6601 - precision: 0.5110 - recall: 0.9877\nEpoch 4: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 307ms/step - acc: 0.5263 - auc: 0.7217 - loss: 0.6600 - precision: 0.5110 - recall: 0.9877 - val_acc: 0.5000 - val_auc: 0.7525 - val_loss: 0.4908 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 5/30\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 301ms/step - acc: 0.5382 - auc: 0.7602 - loss: 0.5868 - precision: 0.5176 - recall: 0.9956 - val_acc: 0.5111 - val_auc: 0.7510 - val_loss: 0.5267 - val_precision: 0.5056 - val_recall: 0.9989 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - acc: 0.5735 - auc: 0.8059 - loss: 0.5382 - precision: 0.5378 - recall: 0.9926\nEpoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 298ms/step - acc: 0.5737 - auc: 0.8061 - loss: 0.5379 - precision: 0.5379 - recall: 0.9925 - val_acc: 0.5185 - val_auc: 0.7229 - val_loss: 0.5271 - val_precision: 0.5095 - val_recall: 0.9894 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 300ms/step - acc: 0.6318 - auc: 0.8592 - loss: 0.4389 - precision: 0.5743 - recall: 0.9954 - val_acc: 0.5989 - val_auc: 0.7458 - val_loss: 0.4049 - val_precision: 0.5579 - val_recall: 0.9534 - learning_rate: 5.0000e-05\nEpoch 8/30\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 298ms/step - acc: 0.6990 - auc: 0.9030 - loss: 0.3796 - precision: 0.6230 - recall: 0.9930 - val_acc: 0.5693 - val_auc: 0.7504 - val_loss: 0.4715 - val_precision: 0.5386 - val_recall: 0.9661 - learning_rate: 5.0000e-05\nEpoch 9/30\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 300ms/step - acc: 0.7147 - auc: 0.9189 - loss: 0.3643 - precision: 0.6360 - recall: 0.9909 - val_acc: 0.6778 - val_auc: 0.7298 - val_loss: 0.3236 - val_precision: 0.6519 - val_recall: 0.7630 - learning_rate: 5.0000e-05\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 264ms/step\nBest threshold: 0.750 (F1: 0.726)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Consolidation_00025238_016.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Consolidation_00020338_001.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Consolidation_00019823_007.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Consolidation_00016064_014.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Consolidation_00006199_002.png\nCompleted at 2025-06-03 16:32:08 UTC\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Train 5\nresults = train_single_class('Edema')\nif results:\n    with open(\"/kaggle/working/Edema_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:32:08.661194Z","iopub.execute_input":"2025-06-03T16:32:08.661484Z","iopub.status.idle":"2025-06-03T16:44:42.855261Z","shell.execute_reply.started":"2025-06-03T16:32:08.661465Z","shell.execute_reply":"2025-06-03T16:44:42.854643Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Edema ===\nStarted at 2025-06-03 16:32:08 UTC\nValidation balance - Pos: 464, Neg: 464\nBuilding model for Edema...\nInitializing model with dummy input...\nTraining samples: 87 batches\nValidation samples: 29 batches\nUsing class weight - positive: 47.84\nEpoch 1/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 1s/step - acc: 0.6078 - auc: 0.6968 - loss: 2.6045 - precision: 0.5686 - recall: 0.8793 - val_acc: 0.5334 - val_auc: 0.8080 - val_loss: 0.7257 - val_precision: 0.8298 - val_recall: 0.0841 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 304ms/step - acc: 0.5642 - auc: 0.7474 - loss: 1.0739 - precision: 0.5334 - recall: 0.9876 - val_acc: 0.6261 - val_auc: 0.6592 - val_loss: 0.2284 - val_precision: 0.6077 - val_recall: 0.7112 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 302ms/step - acc: 0.5573 - auc: 0.7479 - loss: 1.0163 - precision: 0.5294 - recall: 0.9867 - val_acc: 0.5086 - val_auc: 0.7876 - val_loss: 0.9579 - val_precision: 0.5043 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - acc: 0.5870 - auc: 0.8014 - loss: 0.8155 - precision: 0.5468 - recall: 0.9893\nEpoch 4: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 314ms/step - acc: 0.5870 - auc: 0.8013 - loss: 0.8159 - precision: 0.5469 - recall: 0.9893 - val_acc: 0.5506 - val_auc: 0.8460 - val_loss: 0.5544 - val_precision: 0.5268 - val_recall: 0.9957 - learning_rate: 2.0000e-04\nEpoch 5/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 300ms/step - acc: 0.6009 - auc: 0.8295 - loss: 0.7350 - precision: 0.5555 - recall: 0.9927 - val_acc: 0.5269 - val_auc: 0.8232 - val_loss: 0.9455 - val_precision: 0.5139 - val_recall: 0.9957 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - acc: 0.6409 - auc: 0.8623 - loss: 0.6407 - precision: 0.5815 - recall: 0.9920\nEpoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 319ms/step - acc: 0.6410 - auc: 0.8623 - loss: 0.6407 - precision: 0.5816 - recall: 0.9920 - val_acc: 0.6207 - val_auc: 0.8566 - val_loss: 0.6057 - val_precision: 0.5695 - val_recall: 0.9892 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 299ms/step - acc: 0.7011 - auc: 0.8806 - loss: 0.5544 - precision: 0.6255 - recall: 0.9939 - val_acc: 0.6153 - val_auc: 0.8561 - val_loss: 0.5907 - val_precision: 0.5661 - val_recall: 0.9871 - learning_rate: 5.0000e-05\nEpoch 8/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - acc: 0.7030 - auc: 0.8938 - loss: 0.5341 - precision: 0.6267 - recall: 0.9957\nEpoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 318ms/step - acc: 0.7030 - auc: 0.8938 - loss: 0.5341 - precision: 0.6267 - recall: 0.9957 - val_acc: 0.6466 - val_auc: 0.8582 - val_loss: 0.4613 - val_precision: 0.5874 - val_recall: 0.9849 - learning_rate: 5.0000e-05\nEpoch 9/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 318ms/step - acc: 0.7060 - auc: 0.9055 - loss: 0.5149 - precision: 0.6293 - recall: 0.9944 - val_acc: 0.6800 - val_auc: 0.8704 - val_loss: 0.4303 - val_precision: 0.6115 - val_recall: 0.9871 - learning_rate: 2.5000e-05\nEpoch 10/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - acc: 0.7284 - auc: 0.9235 - loss: 0.4292 - precision: 0.6472 - recall: 0.9971\nEpoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 317ms/step - acc: 0.7285 - auc: 0.9235 - loss: 0.4290 - precision: 0.6473 - recall: 0.9971 - val_acc: 0.7047 - val_auc: 0.8764 - val_loss: 0.3821 - val_precision: 0.6323 - val_recall: 0.9784 - learning_rate: 2.5000e-05\nEpoch 11/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 317ms/step - acc: 0.7371 - auc: 0.9448 - loss: 0.3544 - precision: 0.6550 - recall: 0.9972 - val_acc: 0.7112 - val_auc: 0.8780 - val_loss: 0.3758 - val_precision: 0.6384 - val_recall: 0.9741 - learning_rate: 1.2500e-05\nEpoch 12/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - acc: 0.7534 - auc: 0.9449 - loss: 0.3799 - precision: 0.6701 - recall: 0.9926\nEpoch 12: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 317ms/step - acc: 0.7534 - auc: 0.9449 - loss: 0.3802 - precision: 0.6701 - recall: 0.9926 - val_acc: 0.7015 - val_auc: 0.8784 - val_loss: 0.3903 - val_precision: 0.6293 - val_recall: 0.9806 - learning_rate: 1.2500e-05\nEpoch 13/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 300ms/step - acc: 0.7418 - auc: 0.9403 - loss: 0.3697 - precision: 0.6588 - recall: 0.9977 - val_acc: 0.6940 - val_auc: 0.8775 - val_loss: 0.4289 - val_precision: 0.6233 - val_recall: 0.9806 - learning_rate: 6.2500e-06\nEpoch 14/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - acc: 0.7612 - auc: 0.9434 - loss: 0.3460 - precision: 0.6756 - recall: 0.9997\nEpoch 14: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 300ms/step - acc: 0.7612 - auc: 0.9434 - loss: 0.3460 - precision: 0.6756 - recall: 0.9997 - val_acc: 0.7047 - val_auc: 0.8759 - val_loss: 0.4239 - val_precision: 0.6331 - val_recall: 0.9741 - learning_rate: 6.2500e-06\nEpoch 15/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 301ms/step - acc: 0.7723 - auc: 0.9493 - loss: 0.3357 - precision: 0.6862 - recall: 0.9986 - val_acc: 0.7080 - val_auc: 0.8758 - val_loss: 0.4177 - val_precision: 0.6357 - val_recall: 0.9741 - learning_rate: 3.1250e-06\nEpoch 16/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - acc: 0.7817 - auc: 0.9566 - loss: 0.2933 - precision: 0.6949 - recall: 0.9998\nEpoch 16: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 300ms/step - acc: 0.7817 - auc: 0.9566 - loss: 0.2934 - precision: 0.6950 - recall: 0.9998 - val_acc: 0.7134 - val_auc: 0.8771 - val_loss: 0.4034 - val_precision: 0.6402 - val_recall: 0.9741 - learning_rate: 3.1250e-06\nEpoch 17/30\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 300ms/step - acc: 0.7769 - auc: 0.9575 - loss: 0.3405 - precision: 0.6911 - recall: 0.9970 - val_acc: 0.7101 - val_auc: 0.8771 - val_loss: 0.4135 - val_precision: 0.6375 - val_recall: 0.9741 - learning_rate: 1.5625e-06\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step\nBest threshold: 0.800 (F1: 0.821)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Edema_00003715_000.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Edema_00009138_027.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Edema_00012129_003.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Edema_00006653_023.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Edema_00030079_005.png\nCompleted at 2025-06-03 16:44:42 UTC\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Train 6 \nresults = train_single_class('Effusion')\nif results:\n    with open(\"/kaggle/working/Effusion_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:55:18.527164Z","iopub.execute_input":"2025-06-03T16:55:18.527419Z","iopub.status.idle":"2025-06-03T17:29:54.863584Z","shell.execute_reply.started":"2025-06-03T16:55:18.527402Z","shell.execute_reply":"2025-06-03T17:29:54.862157Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Effusion ===\nStarted at 2025-06-03 16:55:18 UTC\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1748969722.346367    1898 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1748969722.347102    1898 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Validation balance - Pos: 2674, Neg: 2674\nBuilding model for Effusion...\nInitializing model with dummy input...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1748969739.604986    1898 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"Training samples: 497 batches\nValidation samples: 168 batches\nUsing class weight - positive: 7.49\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1748969886.315222    1935 service.cc:148] XLA service 0x7b73d40032e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1748969886.316183    1935 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1748969886.316202    1935 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1748969975.537983    1935 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 522ms/step - acc: 0.5860 - auc: 0.6847 - loss: 0.6303 - precision: 0.5518 - recall: 0.9083 - val_acc: 0.6238 - val_auc: 0.8489 - val_loss: 0.2640 - val_precision: 0.5719 - val_recall: 0.9847 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 303ms/step - acc: 0.6420 - auc: 0.7949 - loss: 0.3877 - precision: 0.5872 - recall: 0.9552 - val_acc: 0.5385 - val_auc: 0.8600 - val_loss: 0.2534 - val_precision: 0.5201 - val_recall: 0.9955 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 299ms/step - acc: 0.6545 - auc: 0.8187 - loss: 0.3527 - precision: 0.5956 - recall: 0.9628 - val_acc: 0.6303 - val_auc: 0.8577 - val_loss: 0.2279 - val_precision: 0.5762 - val_recall: 0.9850 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 300ms/step - acc: 0.6737 - auc: 0.8424 - loss: 0.3210 - precision: 0.6094 - recall: 0.9665 - val_acc: 0.5161 - val_auc: 0.8492 - val_loss: 0.3418 - val_precision: 0.5082 - val_recall: 0.9985 - learning_rate: 2.0000e-04\nEpoch 5/30\n\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 299ms/step - acc: 0.6955 - auc: 0.8649 - loss: 0.2931 - precision: 0.6259 - recall: 0.9731 - val_acc: 0.6567 - val_auc: 0.8573 - val_loss: 0.2141 - val_precision: 0.5956 - val_recall: 0.9761 - learning_rate: 2.0000e-04\nEpoch 6/30\n\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 302ms/step - acc: 0.7185 - auc: 0.8859 - loss: 0.2685 - precision: 0.6442 - recall: 0.9758 - val_acc: 0.6522 - val_auc: 0.8633 - val_loss: 0.2060 - val_precision: 0.5916 - val_recall: 0.9832 - learning_rate: 2.0000e-04\nEpoch 7/30\n\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 300ms/step - acc: 0.7474 - auc: 0.9091 - loss: 0.2399 - precision: 0.6692 - recall: 0.9789 - val_acc: 0.6870 - val_auc: 0.8501 - val_loss: 0.1755 - val_precision: 0.6209 - val_recall: 0.9600 - learning_rate: 2.0000e-04\nEpoch 8/30\n\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 299ms/step - acc: 0.7612 - auc: 0.9187 - loss: 0.2293 - precision: 0.6816 - recall: 0.9797 - val_acc: 0.6874 - val_auc: 0.8457 - val_loss: 0.1983 - val_precision: 0.6210 - val_recall: 0.9615 - learning_rate: 2.0000e-04\nEpoch 9/30\n\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 300ms/step - acc: 0.7887 - auc: 0.9341 - loss: 0.2053 - precision: 0.7086 - recall: 0.9802 - val_acc: 0.7304 - val_auc: 0.8417 - val_loss: 0.1609 - val_precision: 0.6682 - val_recall: 0.9151 - learning_rate: 2.0000e-04\nEpoch 10/30\n\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 299ms/step - acc: 0.7960 - auc: 0.9402 - loss: 0.1970 - precision: 0.7152 - recall: 0.9832 - val_acc: 0.7367 - val_auc: 0.8458 - val_loss: 0.1512 - val_precision: 0.6741 - val_recall: 0.9166 - learning_rate: 2.0000e-04\nEpoch 11/30\n\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 299ms/step - acc: 0.8297 - auc: 0.9576 - loss: 0.1660 - precision: 0.7518 - recall: 0.9841 - val_acc: 0.6331 - val_auc: 0.8252 - val_loss: 0.2482 - val_precision: 0.5802 - val_recall: 0.9630 - learning_rate: 2.0000e-04\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 135ms/step\nBest threshold: 0.650 (F1: 0.796)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Effusion_00011010_015.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Effusion_00025924_006.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Effusion_00013123_007.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Effusion_00003481_000.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Effusion_00012505_008.png\nCompleted at 2025-06-03 17:29:54 UTC\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Train 7\nresults = train_single_class('Emphysema')\nif results:\n    with open(\"/kaggle/working/Emphysema_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T17:29:54.864887Z","iopub.execute_input":"2025-06-03T17:29:54.865110Z","iopub.status.idle":"2025-06-03T17:50:08.245720Z","shell.execute_reply.started":"2025-06-03T17:29:54.865092Z","shell.execute_reply":"2025-06-03T17:50:08.245007Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Emphysema ===\nStarted at 2025-06-03 17:29:54 UTC\nValidation balance - Pos: 479, Neg: 479\nBuilding model for Emphysema...\nInitializing model with dummy input...\nTraining samples: 96 batches\nValidation samples: 30 batches\nUsing class weight - positive: 43.17\nEpoch 1/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 1s/step - acc: 0.5178 - auc: 0.5678 - loss: 3.2316 - precision: 0.5082 - recall: 0.8548 - val_acc: 0.5960 - val_auc: 0.7382 - val_loss: 0.3519 - val_precision: 0.8067 - val_recall: 0.2526 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 319ms/step - acc: 0.5168 - auc: 0.6516 - loss: 1.2063 - precision: 0.5070 - recall: 0.9835 - val_acc: 0.5386 - val_auc: 0.7657 - val_loss: 0.4136 - val_precision: 0.5203 - val_recall: 0.9896 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - acc: 0.5175 - auc: 0.6655 - loss: 1.0584 - precision: 0.5073 - recall: 0.9827\nEpoch 3: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 313ms/step - acc: 0.5176 - auc: 0.6658 - loss: 1.0576 - precision: 0.5074 - recall: 0.9827 - val_acc: 0.5042 - val_auc: 0.8147 - val_loss: 0.6737 - val_precision: 0.5021 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 314ms/step - acc: 0.5432 - auc: 0.7764 - loss: 0.8409 - precision: 0.5212 - recall: 0.9848 - val_acc: 0.5052 - val_auc: 0.8219 - val_loss: 0.7232 - val_precision: 0.5026 - val_recall: 0.9979 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - acc: 0.5528 - auc: 0.7943 - loss: 0.8335 - precision: 0.5267 - recall: 0.9886\nEpoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 316ms/step - acc: 0.5529 - auc: 0.7945 - loss: 0.8325 - precision: 0.5268 - recall: 0.9886 - val_acc: 0.5449 - val_auc: 0.8348 - val_loss: 0.6002 - val_precision: 0.5235 - val_recall: 0.9979 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - acc: 0.6056 - auc: 0.8619 - loss: 0.6423 - precision: 0.5583 - recall: 0.9881 - val_acc: 0.5511 - val_auc: 0.8570 - val_loss: 0.5363 - val_precision: 0.5271 - val_recall: 0.9937 - learning_rate: 5.0000e-05\nEpoch 7/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - acc: 0.6293 - auc: 0.8876 - loss: 0.5808 - precision: 0.5734 - recall: 0.9900\nEpoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 298ms/step - acc: 0.6293 - auc: 0.8877 - loss: 0.5803 - precision: 0.5735 - recall: 0.9900 - val_acc: 0.6388 - val_auc: 0.8538 - val_loss: 0.3713 - val_precision: 0.5824 - val_recall: 0.9812 - learning_rate: 5.0000e-05\nEpoch 8/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 316ms/step - acc: 0.6675 - auc: 0.9107 - loss: 0.4827 - precision: 0.5998 - recall: 0.9948 - val_acc: 0.6795 - val_auc: 0.8638 - val_loss: 0.3209 - val_precision: 0.6135 - val_recall: 0.9708 - learning_rate: 2.5000e-05\nEpoch 9/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 300ms/step - acc: 0.7065 - auc: 0.9264 - loss: 0.4317 - precision: 0.6295 - recall: 0.9957 - val_acc: 0.6879 - val_auc: 0.8633 - val_loss: 0.3267 - val_precision: 0.6210 - val_recall: 0.9645 - learning_rate: 2.5000e-05\nEpoch 10/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - acc: 0.7186 - auc: 0.9455 - loss: 0.3709 - precision: 0.6396 - recall: 0.9955\nEpoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 298ms/step - acc: 0.7188 - auc: 0.9455 - loss: 0.3707 - precision: 0.6398 - recall: 0.9955 - val_acc: 0.6785 - val_auc: 0.8625 - val_loss: 0.3819 - val_precision: 0.6121 - val_recall: 0.9749 - learning_rate: 2.5000e-05\nEpoch 11/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 316ms/step - acc: 0.7580 - auc: 0.9541 - loss: 0.3296 - precision: 0.6727 - recall: 0.9988 - val_acc: 0.7119 - val_auc: 0.8679 - val_loss: 0.3360 - val_precision: 0.6404 - val_recall: 0.9666 - learning_rate: 1.2500e-05\nEpoch 12/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - acc: 0.7825 - auc: 0.9608 - loss: 0.2951 - precision: 0.6965 - recall: 0.9973 - val_acc: 0.7276 - val_auc: 0.8681 - val_loss: 0.3200 - val_precision: 0.6548 - val_recall: 0.9624 - learning_rate: 1.2500e-05\nEpoch 13/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 316ms/step - acc: 0.8035 - auc: 0.9685 - loss: 0.2631 - precision: 0.7173 - recall: 0.9970 - val_acc: 0.6879 - val_auc: 0.8705 - val_loss: 0.4016 - val_precision: 0.6187 - val_recall: 0.9791 - learning_rate: 1.2500e-05\nEpoch 14/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - acc: 0.8163 - auc: 0.9737 - loss: 0.2583 - precision: 0.7311 - recall: 0.9963\nEpoch 14: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 299ms/step - acc: 0.8164 - auc: 0.9737 - loss: 0.2581 - precision: 0.7312 - recall: 0.9963 - val_acc: 0.7234 - val_auc: 0.8659 - val_loss: 0.3470 - val_precision: 0.6533 - val_recall: 0.9520 - learning_rate: 1.2500e-05\nEpoch 15/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 299ms/step - acc: 0.7951 - auc: 0.9776 - loss: 0.3911 - precision: 0.7110 - recall: 0.9905 - val_acc: 0.7182 - val_auc: 0.8692 - val_loss: 0.3462 - val_precision: 0.6482 - val_recall: 0.9541 - learning_rate: 6.2500e-06\nEpoch 16/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - acc: 0.8263 - auc: 0.9814 - loss: 0.2131 - precision: 0.7412 - recall: 0.9984\nEpoch 16: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 298ms/step - acc: 0.8264 - auc: 0.9814 - loss: 0.2129 - precision: 0.7414 - recall: 0.9984 - val_acc: 0.7223 - val_auc: 0.8692 - val_loss: 0.3532 - val_precision: 0.6519 - val_recall: 0.9541 - learning_rate: 6.2500e-06\nEpoch 17/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 299ms/step - acc: 0.8259 - auc: 0.9837 - loss: 0.2041 - precision: 0.7414 - recall: 0.9980 - val_acc: 0.7255 - val_auc: 0.8704 - val_loss: 0.3497 - val_precision: 0.6556 - val_recall: 0.9499 - learning_rate: 3.1250e-06\nEpoch 18/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - acc: 0.8344 - auc: 0.9839 - loss: 0.2098 - precision: 0.7516 - recall: 0.9959\nEpoch 18: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 314ms/step - acc: 0.8345 - auc: 0.9840 - loss: 0.2096 - precision: 0.7517 - recall: 0.9959 - val_acc: 0.7296 - val_auc: 0.8712 - val_loss: 0.3392 - val_precision: 0.6594 - val_recall: 0.9499 - learning_rate: 3.1250e-06\nEpoch 19/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 299ms/step - acc: 0.8454 - auc: 0.9878 - loss: 0.1775 - precision: 0.7628 - recall: 0.9990 - val_acc: 0.7296 - val_auc: 0.8710 - val_loss: 0.3513 - val_precision: 0.6594 - val_recall: 0.9499 - learning_rate: 1.5625e-06\nEpoch 20/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - acc: 0.8417 - auc: 0.9854 - loss: 0.1781 - precision: 0.7586 - recall: 0.9994\nEpoch 20: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - acc: 0.8419 - auc: 0.9854 - loss: 0.1780 - precision: 0.7588 - recall: 0.9994 - val_acc: 0.7255 - val_auc: 0.8718 - val_loss: 0.3658 - val_precision: 0.6556 - val_recall: 0.9499 - learning_rate: 1.5625e-06\nEpoch 21/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 299ms/step - acc: 0.8454 - auc: 0.9834 - loss: 0.2039 - precision: 0.7642 - recall: 0.9965 - val_acc: 0.7286 - val_auc: 0.8717 - val_loss: 0.3641 - val_precision: 0.6585 - val_recall: 0.9499 - learning_rate: 1.0000e-06\nEpoch 22/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - acc: 0.8450 - auc: 0.9859 - loss: 0.1804 - precision: 0.7622 - recall: 0.9992 - val_acc: 0.7296 - val_auc: 0.8718 - val_loss: 0.3625 - val_precision: 0.6594 - val_recall: 0.9499 - learning_rate: 1.0000e-06\nEpoch 23/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 299ms/step - acc: 0.8445 - auc: 0.9844 - loss: 0.2334 - precision: 0.7635 - recall: 0.9956 - val_acc: 0.7338 - val_auc: 0.8713 - val_loss: 0.3476 - val_precision: 0.6642 - val_recall: 0.9457 - learning_rate: 1.0000e-06\nEpoch 24/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - acc: 0.8541 - auc: 0.9875 - loss: 0.1684 - precision: 0.7733 - recall: 0.9992 - val_acc: 0.7338 - val_auc: 0.8724 - val_loss: 0.3510 - val_precision: 0.6633 - val_recall: 0.9499 - learning_rate: 1.0000e-06\nEpoch 25/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 298ms/step - acc: 0.8514 - auc: 0.9881 - loss: 0.1553 - precision: 0.7702 - recall: 0.9992 - val_acc: 0.7328 - val_auc: 0.8724 - val_loss: 0.3604 - val_precision: 0.6623 - val_recall: 0.9499 - learning_rate: 1.0000e-06\nEpoch 26/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - acc: 0.8682 - auc: 0.9861 - loss: 0.1981 - precision: 0.7921 - recall: 0.9957 - val_acc: 0.7307 - val_auc: 0.8726 - val_loss: 0.3641 - val_precision: 0.6604 - val_recall: 0.9499 - learning_rate: 1.0000e-06\nEpoch 27/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - acc: 0.8520 - auc: 0.9871 - loss: 0.1637 - precision: 0.7707 - recall: 0.9994 - val_acc: 0.7359 - val_auc: 0.8727 - val_loss: 0.3513 - val_precision: 0.6652 - val_recall: 0.9499 - learning_rate: 1.0000e-06\nEpoch 28/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 299ms/step - acc: 0.8507 - auc: 0.9901 - loss: 0.1533 - precision: 0.7689 - recall: 1.0000 - val_acc: 0.7380 - val_auc: 0.8722 - val_loss: 0.3545 - val_precision: 0.6672 - val_recall: 0.9499 - learning_rate: 1.0000e-06\nEpoch 29/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 299ms/step - acc: 0.8525 - auc: 0.9874 - loss: 0.1825 - precision: 0.7725 - recall: 0.9972 - val_acc: 0.7370 - val_auc: 0.8721 - val_loss: 0.3474 - val_precision: 0.6677 - val_recall: 0.9436 - learning_rate: 1.0000e-06\nEpoch 30/30\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 299ms/step - acc: 0.8622 - auc: 0.9909 - loss: 0.1394 - precision: 0.7830 - recall: 0.9995 - val_acc: 0.7390 - val_auc: 0.8720 - val_loss: 0.3468 - val_precision: 0.6696 - val_recall: 0.9436 - learning_rate: 1.0000e-06\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 451ms/step\nBest threshold: 0.750 (F1: 0.804)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Emphysema_00021109_005.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Emphysema_00026267_006.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Emphysema_00001799_000.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Emphysema_00011104_009.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Emphysema_00020297_003.png\nCompleted at 2025-06-03 17:50:08 UTC\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Train 8\nresults = train_single_class('Fibrosis')\nif results:\n    with open(\"/kaggle/working/Fibrosis_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T17:50:08.247529Z","iopub.execute_input":"2025-06-03T17:50:08.247821Z","iopub.status.idle":"2025-06-03T18:01:10.723108Z","shell.execute_reply.started":"2025-06-03T17:50:08.247800Z","shell.execute_reply":"2025-06-03T18:01:10.722457Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Fibrosis ===\nStarted at 2025-06-03 17:50:08 UTC\nValidation balance - Pos: 329, Neg: 329\nBuilding model for Fibrosis...\nInitializing model with dummy input...\nTraining samples: 64 batches\nValidation samples: 21 batches\nUsing class weight - positive: 65.76\nEpoch 1/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 2s/step - acc: 0.5265 - auc: 0.5611 - loss: 6.3215 - precision: 0.5290 - recall: 0.7780 - val_acc: 0.5000 - val_auc: 0.5977 - val_loss: 1.3622 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 327ms/step - acc: 0.5192 - auc: 0.6391 - loss: 1.2959 - precision: 0.5167 - recall: 0.9876 - val_acc: 0.6140 - val_auc: 0.6674 - val_loss: 0.2514 - val_precision: 0.5854 - val_recall: 0.7812 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 325ms/step - acc: 0.5217 - auc: 0.6666 - loss: 1.2570 - precision: 0.5181 - recall: 0.9830 - val_acc: 0.5015 - val_auc: 0.6887 - val_loss: 0.6908 - val_precision: 0.5008 - val_recall: 0.9939 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - acc: 0.5375 - auc: 0.6794 - loss: 1.0363 - precision: 0.5261 - recall: 0.9982\nEpoch 4: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 319ms/step - acc: 0.5374 - auc: 0.6795 - loss: 1.0364 - precision: 0.5260 - recall: 0.9981 - val_acc: 0.5137 - val_auc: 0.7174 - val_loss: 0.8759 - val_precision: 0.5069 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 5/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 319ms/step - acc: 0.5755 - auc: 0.7512 - loss: 0.8930 - precision: 0.5478 - recall: 0.9966 - val_acc: 0.5426 - val_auc: 0.7453 - val_loss: 0.5515 - val_precision: 0.5224 - val_recall: 0.9939 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - acc: 0.5712 - auc: 0.8157 - loss: 0.7574 - precision: 0.5450 - recall: 0.9981\nEpoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 322ms/step - acc: 0.5711 - auc: 0.8156 - loss: 0.7579 - precision: 0.5448 - recall: 0.9981 - val_acc: 0.5258 - val_auc: 0.7554 - val_loss: 0.6509 - val_precision: 0.5133 - val_recall: 1.0000 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 324ms/step - acc: 0.5913 - auc: 0.8202 - loss: 0.7302 - precision: 0.5578 - recall: 0.9962 - val_acc: 0.5304 - val_auc: 0.7558 - val_loss: 0.6963 - val_precision: 0.5158 - val_recall: 0.9939 - learning_rate: 5.0000e-05\nEpoch 8/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - acc: 0.5833 - auc: 0.8343 - loss: 0.9653 - precision: 0.5525 - recall: 0.9923\nEpoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 296ms/step - acc: 0.5831 - auc: 0.8342 - loss: 0.9636 - precision: 0.5523 - recall: 0.9923 - val_acc: 0.5289 - val_auc: 0.7340 - val_loss: 0.5896 - val_precision: 0.5150 - val_recall: 0.9909 - learning_rate: 5.0000e-05\nEpoch 9/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 298ms/step - acc: 0.5879 - auc: 0.8531 - loss: 0.6278 - precision: 0.5548 - recall: 0.9989 - val_acc: 0.5471 - val_auc: 0.7510 - val_loss: 0.6374 - val_precision: 0.5251 - val_recall: 0.9848 - learning_rate: 2.5000e-05\nEpoch 10/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - acc: 0.6362 - auc: 0.8759 - loss: 0.5838 - precision: 0.5856 - recall: 1.0000\nEpoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 322ms/step - acc: 0.6360 - auc: 0.8761 - loss: 0.5837 - precision: 0.5854 - recall: 1.0000 - val_acc: 0.5578 - val_auc: 0.7618 - val_loss: 0.5744 - val_precision: 0.5311 - val_recall: 0.9848 - learning_rate: 2.5000e-05\nEpoch 11/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 322ms/step - acc: 0.6523 - auc: 0.8921 - loss: 0.6279 - precision: 0.5969 - recall: 0.9962 - val_acc: 0.5684 - val_auc: 0.7670 - val_loss: 0.5532 - val_precision: 0.5377 - val_recall: 0.9757 - learning_rate: 1.2500e-05\nEpoch 12/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - acc: 0.6477 - auc: 0.8996 - loss: 0.5392 - precision: 0.5933 - recall: 0.9976\nEpoch 12: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 298ms/step - acc: 0.6476 - auc: 0.8997 - loss: 0.5390 - precision: 0.5932 - recall: 0.9976 - val_acc: 0.5729 - val_auc: 0.7622 - val_loss: 0.5684 - val_precision: 0.5403 - val_recall: 0.9787 - learning_rate: 1.2500e-05\nEpoch 13/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 298ms/step - acc: 0.6528 - auc: 0.9003 - loss: 0.5625 - precision: 0.5973 - recall: 0.9949 - val_acc: 0.5851 - val_auc: 0.7634 - val_loss: 0.5527 - val_precision: 0.5478 - val_recall: 0.9757 - learning_rate: 6.2500e-06\nEpoch 14/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - acc: 0.6560 - auc: 0.8999 - loss: 0.5611 - precision: 0.5992 - recall: 0.9990\nEpoch 14: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 297ms/step - acc: 0.6558 - auc: 0.9001 - loss: 0.5606 - precision: 0.5989 - recall: 0.9990 - val_acc: 0.5866 - val_auc: 0.7607 - val_loss: 0.5654 - val_precision: 0.5487 - val_recall: 0.9757 - learning_rate: 6.2500e-06\nEpoch 15/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 297ms/step - acc: 0.6732 - auc: 0.9130 - loss: 0.4805 - precision: 0.6111 - recall: 0.9992 - val_acc: 0.5912 - val_auc: 0.7622 - val_loss: 0.5620 - val_precision: 0.5515 - val_recall: 0.9757 - learning_rate: 3.1250e-06\nEpoch 16/30\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - acc: 0.6619 - auc: 0.9148 - loss: 0.4896 - precision: 0.6031 - recall: 0.9996\nEpoch 16: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 298ms/step - acc: 0.6618 - auc: 0.9149 - loss: 0.4894 - precision: 0.6029 - recall: 0.9995 - val_acc: 0.5927 - val_auc: 0.7631 - val_loss: 0.5464 - val_precision: 0.5530 - val_recall: 0.9666 - learning_rate: 3.1250e-06\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 636ms/step\nBest threshold: 0.750 (F1: 0.729)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Fibrosis_00026413_000.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Fibrosis_00018335_004.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Fibrosis_00006669_000.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Fibrosis_00014429_015.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Fibrosis_00007034_039.png\nCompleted at 2025-06-03 18:01:10 UTC\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"#rain 9\nresults = train_single_class('Hernia')\nif results:\n    with open(\"/kaggle/working/Hernia_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:01:10.723919Z","iopub.execute_input":"2025-06-03T18:01:10.724147Z","iopub.status.idle":"2025-06-03T18:07:18.910110Z","shell.execute_reply.started":"2025-06-03T18:01:10.724128Z","shell.execute_reply":"2025-06-03T18:07:18.909249Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Hernia ===\nStarted at 2025-06-03 18:01:10 UTC\nValidation balance - Pos: 41, Neg: 41\nBuilding model for Hernia...\nInitializing model with dummy input...\nTraining samples: 9 batches\nValidation samples: 3 batches\nUsing class weight - positive: 481.09\nEpoch 1/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 13s/step - acc: 0.5955 - auc: 0.5763 - loss: 119.1388 - precision: 0.5612 - recall: 0.5336 - val_acc: 0.5000 - val_auc: 0.7136 - val_loss: 1.3770 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 486ms/step - acc: 0.6591 - auc: 0.8061 - loss: 17.8224 - precision: 0.5909 - recall: 0.8808 - val_acc: 0.5000 - val_auc: 0.7406 - val_loss: 1.8141 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - acc: 0.6698 - auc: 0.8488 - loss: 4.9532 - precision: 0.5904 - recall: 0.9605\nEpoch 3: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 503ms/step - acc: 0.6693 - auc: 0.8484 - loss: 4.9206 - precision: 0.5915 - recall: 0.9616 - val_acc: 0.5000 - val_auc: 0.7805 - val_loss: 2.0227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 504ms/step - acc: 0.6702 - auc: 0.9092 - loss: 1.2192 - precision: 0.5873 - recall: 0.9978 - val_acc: 0.5000 - val_auc: 0.8212 - val_loss: 1.8804 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - acc: 0.6807 - auc: 0.9026 - loss: 2.1986 - precision: 0.5931 - recall: 0.9947\nEpoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 492ms/step - acc: 0.6815 - auc: 0.9027 - loss: 2.1928 - precision: 0.5956 - recall: 0.9945 - val_acc: 0.5000 - val_auc: 0.8447 - val_loss: 1.7112 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 493ms/step - acc: 0.6782 - auc: 0.9077 - loss: 2.0132 - precision: 0.5929 - recall: 0.9986 - val_acc: 0.5000 - val_auc: 0.8456 - val_loss: 1.4514 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-05\nEpoch 7/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 500ms/step - acc: 0.6777 - auc: 0.9080 - loss: 0.9664 - precision: 0.5926 - recall: 1.0000 - val_acc: 0.5000 - val_auc: 0.8554 - val_loss: 1.2060 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-05\nEpoch 8/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 491ms/step - acc: 0.6665 - auc: 0.9151 - loss: 0.8201 - precision: 0.5842 - recall: 1.0000 - val_acc: 0.5000 - val_auc: 0.8584 - val_loss: 0.9671 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-05\nEpoch 9/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 501ms/step - acc: 0.6656 - auc: 0.9293 - loss: 0.9078 - precision: 0.5843 - recall: 0.9945 - val_acc: 0.5000 - val_auc: 0.8688 - val_loss: 0.7600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-05\nEpoch 10/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 303ms/step - acc: 0.6534 - auc: 0.9324 - loss: 0.7236 - precision: 0.5750 - recall: 1.0000 - val_acc: 0.5122 - val_auc: 0.8635 - val_loss: 0.5755 - val_precision: 1.0000 - val_recall: 0.0244 - learning_rate: 5.0000e-05\nEpoch 11/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 302ms/step - acc: 0.6638 - auc: 0.9422 - loss: 0.6026 - precision: 0.5822 - recall: 1.0000 - val_acc: 0.5122 - val_auc: 0.8632 - val_loss: 0.4345 - val_precision: 1.0000 - val_recall: 0.0244 - learning_rate: 5.0000e-05\nEpoch 12/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 299ms/step - acc: 0.6869 - auc: 0.9257 - loss: 0.6194 - precision: 0.5998 - recall: 1.0000 - val_acc: 0.5976 - val_auc: 0.8623 - val_loss: 0.3294 - val_precision: 1.0000 - val_recall: 0.1951 - learning_rate: 5.0000e-05\nEpoch 13/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 299ms/step - acc: 0.6531 - auc: 0.9153 - loss: 0.8063 - precision: 0.5748 - recall: 1.0000 - val_acc: 0.6707 - val_auc: 0.8587 - val_loss: 0.2545 - val_precision: 1.0000 - val_recall: 0.3415 - learning_rate: 5.0000e-05\nEpoch 14/30\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 300ms/step - acc: 0.6585 - auc: 0.9450 - loss: 0.6101 - precision: 0.5783 - recall: 1.0000 - val_acc: 0.7073 - val_auc: 0.8614 - val_loss: 0.2028 - val_precision: 0.9048 - val_recall: 0.4634 - learning_rate: 5.0000e-05\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6s/step\nBest threshold: 0.100 (F1: 0.711)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Hernia_00015644_000.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Hernia_00018120_000.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Hernia_00000284_003.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Hernia_00004563_001.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Hernia_00020286_036.png\nCompleted at 2025-06-03 18:07:18 UTC\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Train 10\nresults = train_single_class('Infiltration')\nif results:\n    with open(\"/kaggle/working/Infiltration_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T02:00:08.543020Z","iopub.execute_input":"2025-06-04T02:00:08.543254Z","iopub.status.idle":"2025-06-04T02:28:58.059942Z","shell.execute_reply.started":"2025-06-04T02:00:08.543240Z","shell.execute_reply":"2025-06-04T02:28:58.059251Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Infiltration ===\nStarted at 2025-06-04 02:00:08 UTC\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1749002413.122091      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1749002413.122873      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Validation balance - Pos: 4000, Neg: 4000\nBuilding model for Infiltration...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nInitializing model with dummy input...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1749002438.983988      31 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"Training samples: 743 batches\nValidation samples: 250 batches\nUsing class weight - positive: 4.68\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1749002604.863909      99 service.cc:148] XLA service 0x7bb64c0035b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1749002604.864767      99 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1749002604.864874      99 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1749002695.269365      99 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m743/743\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 477ms/step - acc: 0.5170 - auc: 0.5378 - loss: 0.7142 - precision: 0.5127 - recall: 0.8113 - val_acc: 0.5000 - val_auc: 0.5483 - val_loss: 4.1339 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m743/743\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 339ms/step - acc: 0.5176 - auc: 0.5911 - loss: 0.4220 - precision: 0.5108 - recall: 0.9270 - val_acc: 0.5394 - val_auc: 0.6838 - val_loss: 0.1969 - val_precision: 0.5208 - val_recall: 0.9852 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m743/743\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 339ms/step - acc: 0.5185 - auc: 0.6100 - loss: 0.3890 - precision: 0.5111 - recall: 0.9498 - val_acc: 0.5185 - val_auc: 0.6535 - val_loss: 0.4374 - val_precision: 0.5095 - val_recall: 0.9935 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m743/743\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - acc: 0.5214 - auc: 0.6295 - loss: 0.3682 - precision: 0.5125 - recall: 0.9653\nEpoch 4: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\u001b[1m743/743\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 340ms/step - acc: 0.5214 - auc: 0.6295 - loss: 0.3682 - precision: 0.5125 - recall: 0.9653 - val_acc: 0.5215 - val_auc: 0.6889 - val_loss: 0.3047 - val_precision: 0.5111 - val_recall: 0.9942 - learning_rate: 2.0000e-04\nEpoch 5/30\n\u001b[1m743/743\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 339ms/step - acc: 0.5285 - auc: 0.6515 - loss: 0.3438 - precision: 0.5161 - recall: 0.9794 - val_acc: 0.5366 - val_auc: 0.6769 - val_loss: 0.2649 - val_precision: 0.5194 - val_recall: 0.9805 - learning_rate: 1.0000e-04\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 75ms/step\nBest threshold: 0.550 (F1: 0.690)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Infiltration_00017541_009.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Infiltration_00010530_031.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Infiltration_00020213_103.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Infiltration_00004121_003.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Infiltration_00004060_000.png\nCompleted at 2025-06-04 02:28:58 UTC\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Train 11\nresults = train_single_class('Mass')\nif results:\n    with open(\"/kaggle/working/Mass_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T02:28:58.060847Z","iopub.execute_input":"2025-06-04T02:28:58.061535Z","iopub.status.idle":"2025-06-04T02:59:38.304547Z","shell.execute_reply.started":"2025-06-04T02:28:58.061510Z","shell.execute_reply":"2025-06-04T02:59:38.303878Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Mass ===\nStarted at 2025-06-04 02:28:58 UTC\nValidation balance - Pos: 1167, Neg: 1167\nBuilding model for Mass...\nInitializing model with dummy input...\nTraining samples: 218 batches\nValidation samples: 73 batches\nUsing class weight - positive: 18.36\nEpoch 1/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 849ms/step - acc: 0.5080 - auc: 0.5346 - loss: 1.3595 - precision: 0.5065 - recall: 0.9164 - val_acc: 0.5000 - val_auc: 0.5880 - val_loss: 0.9352 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 347ms/step - acc: 0.5124 - auc: 0.5703 - loss: 0.7949 - precision: 0.5080 - recall: 0.9786 - val_acc: 0.5000 - val_auc: 0.7043 - val_loss: 0.4934 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 343ms/step - acc: 0.5234 - auc: 0.6550 - loss: 0.6630 - precision: 0.5138 - recall: 0.9828 - val_acc: 0.5021 - val_auc: 0.7437 - val_loss: 0.3055 - val_precision: 0.5011 - val_recall: 0.9991 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 347ms/step - acc: 0.5286 - auc: 0.7114 - loss: 0.6057 - precision: 0.5166 - recall: 0.9828 - val_acc: 0.5064 - val_auc: 0.7530 - val_loss: 0.3172 - val_precision: 0.5032 - val_recall: 0.9983 - learning_rate: 2.0000e-04\nEpoch 5/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 355ms/step - acc: 0.5675 - auc: 0.7924 - loss: 0.5190 - precision: 0.5384 - recall: 0.9854 - val_acc: 0.5660 - val_auc: 0.7628 - val_loss: 0.2917 - val_precision: 0.5361 - val_recall: 0.9794 - learning_rate: 2.0000e-04\nEpoch 6/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 345ms/step - acc: 0.5961 - auc: 0.8327 - loss: 0.4724 - precision: 0.5557 - recall: 0.9854 - val_acc: 0.5030 - val_auc: 0.7664 - val_loss: 0.7058 - val_precision: 0.5015 - val_recall: 0.9991 - learning_rate: 2.0000e-04\nEpoch 7/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - acc: 0.6383 - auc: 0.8712 - loss: 0.4033 - precision: 0.5829 - recall: 0.9901\nEpoch 7: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 338ms/step - acc: 0.6383 - auc: 0.8712 - loss: 0.4033 - precision: 0.5829 - recall: 0.9901 - val_acc: 0.5544 - val_auc: 0.7563 - val_loss: 0.3505 - val_precision: 0.5295 - val_recall: 0.9760 - learning_rate: 2.0000e-04\nEpoch 8/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 336ms/step - acc: 0.6786 - auc: 0.9099 - loss: 0.3479 - precision: 0.6128 - recall: 0.9879 - val_acc: 0.6088 - val_auc: 0.7421 - val_loss: 0.3588 - val_precision: 0.5689 - val_recall: 0.8980 - learning_rate: 1.0000e-04\nEpoch 9/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - acc: 0.7677 - auc: 0.9526 - loss: 0.2584 - precision: 0.6879 - recall: 0.9885\nEpoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 337ms/step - acc: 0.7678 - auc: 0.9527 - loss: 0.2583 - precision: 0.6880 - recall: 0.9885 - val_acc: 0.6243 - val_auc: 0.7308 - val_loss: 0.4055 - val_precision: 0.5841 - val_recall: 0.8629 - learning_rate: 1.0000e-04\nEpoch 10/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 339ms/step - acc: 0.8237 - auc: 0.9685 - loss: 0.2054 - precision: 0.7447 - recall: 0.9903 - val_acc: 0.5853 - val_auc: 0.7485 - val_loss: 0.5949 - val_precision: 0.5502 - val_recall: 0.9349 - learning_rate: 5.0000e-05\nEpoch 11/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - acc: 0.8608 - auc: 0.9847 - loss: 0.1544 - precision: 0.7871 - recall: 0.9939\nEpoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 345ms/step - acc: 0.8610 - auc: 0.9848 - loss: 0.1543 - precision: 0.7873 - recall: 0.9939 - val_acc: 0.7061 - val_auc: 0.7735 - val_loss: 0.3338 - val_precision: 0.7462 - val_recall: 0.6247 - learning_rate: 5.0000e-05\nEpoch 12/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 344ms/step - acc: 0.8968 - auc: 0.9904 - loss: 0.1230 - precision: 0.8345 - recall: 0.9928 - val_acc: 0.6457 - val_auc: 0.7844 - val_loss: 0.4797 - val_precision: 0.5971 - val_recall: 0.8955 - learning_rate: 2.5000e-05\nEpoch 13/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - acc: 0.9174 - auc: 0.9913 - loss: 0.1156 - precision: 0.8628 - recall: 0.9942\nEpoch 13: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 339ms/step - acc: 0.9174 - auc: 0.9913 - loss: 0.1155 - precision: 0.8629 - recall: 0.9942 - val_acc: 0.6615 - val_auc: 0.7814 - val_loss: 0.4079 - val_precision: 0.6151 - val_recall: 0.8629 - learning_rate: 2.5000e-05\nEpoch 14/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 345ms/step - acc: 0.9384 - auc: 0.9969 - loss: 0.0677 - precision: 0.8925 - recall: 0.9980 - val_acc: 0.6915 - val_auc: 0.7860 - val_loss: 0.3962 - val_precision: 0.6491 - val_recall: 0.8338 - learning_rate: 1.2500e-05\nEpoch 15/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - acc: 0.9748 - auc: 0.9983 - loss: 0.0341 - precision: 0.9527 - recall: 0.9996\nEpoch 15: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 344ms/step - acc: 0.9748 - auc: 0.9983 - loss: 0.0340 - precision: 0.9528 - recall: 0.9996 - val_acc: 0.6958 - val_auc: 0.7904 - val_loss: 0.4011 - val_precision: 0.6575 - val_recall: 0.8175 - learning_rate: 1.2500e-05\nEpoch 16/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 337ms/step - acc: 0.9805 - auc: 0.9966 - loss: 0.0662 - precision: 0.9656 - recall: 0.9967 - val_acc: 0.6859 - val_auc: 0.7903 - val_loss: 0.4280 - val_precision: 0.6447 - val_recall: 0.8286 - learning_rate: 6.2500e-06\nEpoch 17/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - acc: 0.9802 - auc: 0.9986 - loss: 0.0378 - precision: 0.9645 - recall: 0.9975\nEpoch 17: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 339ms/step - acc: 0.9802 - auc: 0.9986 - loss: 0.0377 - precision: 0.9645 - recall: 0.9975 - val_acc: 0.6941 - val_auc: 0.7884 - val_loss: 0.4234 - val_precision: 0.6555 - val_recall: 0.8183 - learning_rate: 6.2500e-06\nEpoch 18/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 339ms/step - acc: 0.9802 - auc: 0.9982 - loss: 0.0707 - precision: 0.9669 - recall: 0.9948 - val_acc: 0.6817 - val_auc: 0.7880 - val_loss: 0.4418 - val_precision: 0.6402 - val_recall: 0.8295 - learning_rate: 3.1250e-06\nEpoch 19/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - acc: 0.9880 - auc: 0.9994 - loss: 0.0247 - precision: 0.9775 - recall: 0.9992\nEpoch 19: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 339ms/step - acc: 0.9880 - auc: 0.9994 - loss: 0.0247 - precision: 0.9775 - recall: 0.9992 - val_acc: 0.6894 - val_auc: 0.7899 - val_loss: 0.4336 - val_precision: 0.6479 - val_recall: 0.8295 - learning_rate: 3.1250e-06\nEpoch 20/30\n\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 338ms/step - acc: 0.9828 - auc: 0.9987 - loss: 0.0297 - precision: 0.9683 - recall: 0.9986 - val_acc: 0.6911 - val_auc: 0.7901 - val_loss: 0.4317 - val_precision: 0.6499 - val_recall: 0.8286 - learning_rate: 1.5625e-06\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 228ms/step\nBest threshold: 0.550 (F1: 0.731)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Mass_00030482_000.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Mass_00008669_000.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Mass_00021375_005.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Mass_00026202_012.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Mass_00018657_017.png\nCompleted at 2025-06-04 02:59:38 UTC\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Train 12\nresults = train_single_class('Nodule')\nif results:\n    with open(\"/kaggle/working/Nodule_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T02:59:38.306272Z","iopub.execute_input":"2025-06-04T02:59:38.306476Z","iopub.status.idle":"2025-06-04T03:20:01.574414Z","shell.execute_reply.started":"2025-06-04T02:59:38.306460Z","shell.execute_reply":"2025-06-04T03:20:01.573807Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Nodule ===\nStarted at 2025-06-04 02:59:38 UTC\nValidation balance - Pos: 1296, Neg: 1296\nBuilding model for Nodule...\nInitializing model with dummy input...\nTraining samples: 238 batches\nValidation samples: 81 batches\nUsing class weight - positive: 16.72\nEpoch 1/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 395ms/step - acc: 0.5071 - auc: 0.5303 - loss: 1.5164 - precision: 0.5103 - recall: 0.8560 - val_acc: 0.5000 - val_auc: 0.5756 - val_loss: 0.6341 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 347ms/step - acc: 0.5111 - auc: 0.5694 - loss: 0.7569 - precision: 0.5089 - recall: 0.9748 - val_acc: 0.5000 - val_auc: 0.6377 - val_loss: 0.5011 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 346ms/step - acc: 0.5091 - auc: 0.5879 - loss: 0.6952 - precision: 0.5078 - recall: 0.9831 - val_acc: 0.5000 - val_auc: 0.7053 - val_loss: 0.3394 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 338ms/step - acc: 0.5112 - auc: 0.6451 - loss: 0.6407 - precision: 0.5089 - recall: 0.9846 - val_acc: 0.5004 - val_auc: 0.6938 - val_loss: 0.3633 - val_precision: 0.5002 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 5/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - acc: 0.5212 - auc: 0.6866 - loss: 0.5920 - precision: 0.5141 - recall: 0.9880\nEpoch 5: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 339ms/step - acc: 0.5212 - auc: 0.6867 - loss: 0.5919 - precision: 0.5141 - recall: 0.9880 - val_acc: 0.5004 - val_auc: 0.6593 - val_loss: 0.8367 - val_precision: 0.5002 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 6/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 336ms/step - acc: 0.5323 - auc: 0.7386 - loss: 0.5507 - precision: 0.5200 - recall: 0.9925 - val_acc: 0.5008 - val_auc: 0.6877 - val_loss: 0.6100 - val_precision: 0.5004 - val_recall: 1.0000 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - acc: 0.5667 - auc: 0.7746 - loss: 0.5162 - precision: 0.5394 - recall: 0.9891\nEpoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 346ms/step - acc: 0.5668 - auc: 0.7748 - loss: 0.5160 - precision: 0.5394 - recall: 0.9891 - val_acc: 0.5428 - val_auc: 0.7103 - val_loss: 0.3640 - val_precision: 0.5232 - val_recall: 0.9660 - learning_rate: 1.0000e-04\nEpoch 8/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 338ms/step - acc: 0.6293 - auc: 0.8613 - loss: 0.4131 - precision: 0.5783 - recall: 0.9922 - val_acc: 0.5934 - val_auc: 0.6907 - val_loss: 0.3260 - val_precision: 0.5615 - val_recall: 0.8526 - learning_rate: 5.0000e-05\nEpoch 9/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 338ms/step - acc: 0.6932 - auc: 0.8955 - loss: 0.3722 - precision: 0.6257 - recall: 0.9839 - val_acc: 0.6011 - val_auc: 0.7080 - val_loss: 0.4094 - val_precision: 0.5666 - val_recall: 0.8596 - learning_rate: 5.0000e-05\nEpoch 10/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - acc: 0.7640 - auc: 0.9386 - loss: 0.2790 - precision: 0.6851 - recall: 0.9918\nEpoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 339ms/step - acc: 0.7641 - auc: 0.9386 - loss: 0.2788 - precision: 0.6852 - recall: 0.9918 - val_acc: 0.5779 - val_auc: 0.6810 - val_loss: 0.6546 - val_precision: 0.5463 - val_recall: 0.9198 - learning_rate: 5.0000e-05\nEpoch 11/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 337ms/step - acc: 0.8109 - auc: 0.9625 - loss: 0.2229 - precision: 0.7324 - recall: 0.9888 - val_acc: 0.5980 - val_auc: 0.7019 - val_loss: 0.4794 - val_precision: 0.5664 - val_recall: 0.8364 - learning_rate: 2.5000e-05\nEpoch 12/30\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - acc: 0.8699 - auc: 0.9834 - loss: 0.1668 - precision: 0.7993 - recall: 0.9932\nEpoch 12: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 339ms/step - acc: 0.8700 - auc: 0.9834 - loss: 0.1666 - precision: 0.7994 - recall: 0.9932 - val_acc: 0.5961 - val_auc: 0.6967 - val_loss: 0.5869 - val_precision: 0.5639 - val_recall: 0.8480 - learning_rate: 2.5000e-05\n\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step\nBest threshold: 0.600 (F1: 0.683)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Nodule_00010294_047.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Nodule_00023643_000.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Nodule_00008742_002.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Nodule_00013249_039.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Nodule_00018237_002.png\nCompleted at 2025-06-04 03:20:01 UTC\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Train 13\nresults = train_single_class('Pleural_Thickening')\nif results:\n    with open(\"/kaggle/working/Pleural_Thickening_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T03:20:01.575142Z","iopub.execute_input":"2025-06-04T03:20:01.575487Z","iopub.status.idle":"2025-06-04T03:32:50.697437Z","shell.execute_reply.started":"2025-06-04T03:20:01.575470Z","shell.execute_reply":"2025-06-04T03:32:50.696664Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Pleural_Thickening ===\nStarted at 2025-06-04 03:20:01 UTC\nValidation balance - Pos: 681, Neg: 681\nBuilding model for Pleural_Thickening...\nInitializing model with dummy input...\nTraining samples: 126 batches\nValidation samples: 43 batches\nUsing class weight - positive: 32.53\nEpoch 1/30\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 1s/step - acc: 0.5112 - auc: 0.5445 - loss: 1.6877 - precision: 0.5063 - recall: 0.9058 - val_acc: 0.5007 - val_auc: 0.5889 - val_loss: 0.4711 - val_precision: 0.5004 - val_recall: 0.9971 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 367ms/step - acc: 0.5105 - auc: 0.6076 - loss: 0.9869 - precision: 0.5054 - recall: 0.9852 - val_acc: 0.5000 - val_auc: 0.6211 - val_loss: 1.1078 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - acc: 0.5108 - auc: 0.6150 - loss: 0.8982 - precision: 0.5055 - recall: 0.9881\nEpoch 3: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 345ms/step - acc: 0.5108 - auc: 0.6150 - loss: 0.8981 - precision: 0.5055 - recall: 0.9881 - val_acc: 0.5000 - val_auc: 0.7043 - val_loss: 0.6779 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 353ms/step - acc: 0.5068 - auc: 0.6574 - loss: 0.8114 - precision: 0.5035 - recall: 0.9890 - val_acc: 0.5044 - val_auc: 0.7378 - val_loss: 0.4735 - val_precision: 0.5022 - val_recall: 1.0000 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - acc: 0.5352 - auc: 0.7512 - loss: 0.6716 - precision: 0.5184 - recall: 0.9936\nEpoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 351ms/step - acc: 0.5352 - auc: 0.7512 - loss: 0.6716 - precision: 0.5184 - recall: 0.9936 - val_acc: 0.5007 - val_auc: 0.7217 - val_loss: 0.5678 - val_precision: 0.5004 - val_recall: 1.0000 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 331ms/step - acc: 0.5570 - auc: 0.7951 - loss: 0.6373 - precision: 0.5306 - recall: 0.9891 - val_acc: 0.5345 - val_auc: 0.7258 - val_loss: 0.4647 - val_precision: 0.5180 - val_recall: 0.9941 - learning_rate: 5.0000e-05\nEpoch 7/30\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 344ms/step - acc: 0.5999 - auc: 0.8394 - loss: 0.5466 - precision: 0.5558 - recall: 0.9966 - val_acc: 0.5969 - val_auc: 0.7279 - val_loss: 0.3606 - val_precision: 0.5587 - val_recall: 0.9222 - learning_rate: 5.0000e-05\nEpoch 8/30\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 335ms/step - acc: 0.6511 - auc: 0.8909 - loss: 0.4631 - precision: 0.5897 - recall: 0.9936 - val_acc: 0.5338 - val_auc: 0.7108 - val_loss: 0.5848 - val_precision: 0.5178 - val_recall: 0.9838 - learning_rate: 5.0000e-05\nEpoch 9/30\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - acc: 0.6859 - auc: 0.9223 - loss: 0.3828 - precision: 0.6153 - recall: 0.9946\nEpoch 9: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 341ms/step - acc: 0.6861 - auc: 0.9223 - loss: 0.3827 - precision: 0.6154 - recall: 0.9946 - val_acc: 0.5492 - val_auc: 0.7059 - val_loss: 0.8312 - val_precision: 0.5267 - val_recall: 0.9706 - learning_rate: 5.0000e-05\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 344ms/step\nBest threshold: 0.700 (F1: 0.705)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Pleural_Thickening_00028762_001.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Pleural_Thickening_00009067_005.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Pleural_Thickening_00012732_000.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Pleural_Thickening_00004735_012.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Pleural_Thickening_00022415_006.png\nCompleted at 2025-06-04 03:32:50 UTC\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Train 14\nresults = train_single_class('Pneumonia')\nif results:\n    with open(\"/kaggle/working/Pneumonia_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T03:32:50.698298Z","iopub.execute_input":"2025-06-04T03:32:50.698606Z","iopub.status.idle":"2025-06-04T03:39:43.893272Z","shell.execute_reply.started":"2025-06-04T03:32:50.698561Z","shell.execute_reply":"2025-06-04T03:39:43.892690Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Pneumonia ===\nStarted at 2025-06-04 03:32:50 UTC\nValidation balance - Pos: 285, Neg: 285\nBuilding model for Pneumonia...\nInitializing model with dummy input...\nTraining samples: 54 batches\nValidation samples: 18 batches\nUsing class weight - positive: 78.03\nEpoch 1/30\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 2s/step - acc: 0.5051 - auc: 0.5513 - loss: 3.6161 - precision: 0.4945 - recall: 0.9060 - val_acc: 0.5000 - val_auc: 0.6144 - val_loss: 0.9370 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04\nEpoch 2/30\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 379ms/step - acc: 0.4903 - auc: 0.5655 - loss: 1.5228 - precision: 0.4890 - recall: 0.9893 - val_acc: 0.5333 - val_auc: 0.6360 - val_loss: 0.4240 - val_precision: 0.5176 - val_recall: 0.9825 - learning_rate: 2.0000e-04\nEpoch 3/30\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 385ms/step - acc: 0.4938 - auc: 0.6104 - loss: 1.4112 - precision: 0.4908 - recall: 0.9944 - val_acc: 0.5000 - val_auc: 0.6608 - val_loss: 1.0051 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 4/30\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - acc: 0.4966 - auc: 0.6508 - loss: 1.1752 - precision: 0.4921 - recall: 0.9975\nEpoch 4: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 328ms/step - acc: 0.4969 - auc: 0.6508 - loss: 1.1746 - precision: 0.4924 - recall: 0.9975 - val_acc: 0.5000 - val_auc: 0.6304 - val_loss: 0.9986 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\nEpoch 5/30\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 326ms/step - acc: 0.5084 - auc: 0.7114 - loss: 1.0357 - precision: 0.4982 - recall: 0.9982 - val_acc: 0.5000 - val_auc: 0.6551 - val_loss: 0.9518 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 756ms/step\nBest threshold: 0.850 (F1: 0.693)\nGenerating GradCAM visualizations...\nProcessing image 1/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Pneumonia_00016291_049.png\nProcessing image 2/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Pneumonia_00000459_041.png\nProcessing image 3/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Pneumonia_00005935_000.png\nProcessing image 4/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Pneumonia_00027726_053.png\nProcessing image 5/5...\nInput shape: (1, 224, 224, 3)\nHeatmap shape: (7, 7)\nSaved visualization to /kaggle/working/gradcam/Pneumonia_00026769_006.png\nCompleted at 2025-06-04 03:39:43 UTC\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Train 15\nresults = train_single_class('Pneumothorax')\nif results:\n    with open(\"/kaggle/working/Pneumothorax_metrics.json\", \"w\") as f:\n        json.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T03:39:43.895111Z","iopub.execute_input":"2025-06-04T03:39:43.895376Z"}},"outputs":[{"name":"stdout","text":"\n=== Training model for: Pneumothorax ===\nStarted at 2025-06-04 03:39:43 UTC\nValidation balance - Pos: 1003, Neg: 1003\nBuilding model for Pneumothorax...\nInitializing model with dummy input...\nTraining samples: 203 batches\nValidation samples: 63 batches\nUsing class weight - positive: 19.86\nEpoch 1/30\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}